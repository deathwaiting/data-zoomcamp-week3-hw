{
    "cells": [
     {
      "cell_type": "code",
      "execution_count": 4,
      "id": "51857ad8-6cf9-43ae-8a8d-7c1ad3edeb97",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "+----------+-------------+--------------------+------------+\n",
         "|LocationID|      Borough|                Zone|service_zone|\n",
         "+----------+-------------+--------------------+------------+\n",
         "|         1|          EWR|      Newark Airport|         EWR|\n",
         "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
         "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
         "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
         "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
         "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
         "|         7|       Queens|             Astoria|   Boro Zone|\n",
         "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
         "|         9|       Queens|          Auburndale|   Boro Zone|\n",
         "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
         "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
         "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
         "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
         "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
         "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
         "|        16|       Queens|             Bayside|   Boro Zone|\n",
         "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
         "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
         "|        19|       Queens|           Bellerose|   Boro Zone|\n",
         "|        20|        Bronx|             Belmont|   Boro Zone|\n",
         "+----------+-------------+--------------------+------------+\n",
         "only showing top 20 rows\n",
         "\n"
        ]
       }
      ],
      "source": [
       "import pyspark\n",
       "from pyspark.sql import SparkSession\n",
       "\n",
       "spark = SparkSession.builder \\\n",
       "    .master(\"local[*]\") \\\n",
       "    .appName('test') \\\n",
       "    .getOrCreate()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bf9c284d-e87b-4ec1-a6f5-283ba71444e9",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "--2024-03-04 22:02:29--  http://wget/\n",
         "Resolving wget (wget)... failed: Name or service not known.\n",
         "wget: unable to resolve host address ‘wget’\n",
         "--2024-03-04 22:02:30--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
         "Resolving github.com (github.com)... 140.82.121.4\n",
         "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
         "HTTP request sent, awaiting response... 302 Found\n",
         "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T200230Z&X-Amz-Expires=300&X-Amz-Signature=4aa36e61772619c258c58dca7a8293ea378bb727872d5db7db72528b76104461&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
         "--2024-03-04 22:02:30--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T200230Z&X-Amz-Expires=300&X-Amz-Signature=4aa36e61772619c258c58dca7a8293ea378bb727872d5db7db72528b76104461&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
         "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
         "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
         "HTTP request sent, awaiting response... 200 OK\n",
         "Length: 19375751 (18M) [application/octet-stream]\n",
         "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
         "\n",
         "fhv_tripdata_2019-1 100%[===================>]  18.48M  3.40MB/s    in 5.4s    \n",
         "\n",
         "2024-03-04 22:02:36 (3.43 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
         "\n",
         "FINISHED --2024-03-04 22:02:36--\n",
         "Total wall clock time: 7.9s\n",
         "Downloaded: 1 files, 18M in 5.4s (3.43 MB/s)\n"
        ]
       }
      ],
      "source": [
       " !wget wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f11596e8-c56d-4588-b91c-7012e307ebff",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
         "|dispatching_base_num|    pickup_datetime|   dropOff_datetime|PUlocationID|DOlocationID|SR_Flag|Affiliated_base_number|\n",
         "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
         "|              B00009|2019-10-01 00:23:00|2019-10-01 00:35:00|         264|         264|   null|                B00009|\n",
         "|              B00013|2019-10-01 00:11:29|2019-10-01 00:13:22|         264|         264|   null|                B00013|\n",
         "|              B00014|2019-10-01 00:11:43|2019-10-01 00:37:20|         264|         264|   null|                B00014|\n",
         "|              B00014|2019-10-01 00:56:29|2019-10-01 00:57:47|         264|         264|   null|                B00014|\n",
         "|              B00014|2019-10-01 00:23:09|2019-10-01 00:28:27|         264|         264|   null|                B00014|\n",
         "|     B00021         |2019-10-01 00:00:48|2019-10-01 00:07:12|         129|         129|   null|       B00021         |\n",
         "|     B00021         |2019-10-01 00:47:23|2019-10-01 00:53:25|          57|          57|   null|       B00021         |\n",
         "|     B00021         |2019-10-01 00:10:06|2019-10-01 00:19:50|         173|         173|   null|       B00021         |\n",
         "|     B00021         |2019-10-01 00:51:37|2019-10-01 01:06:14|         226|         226|   null|       B00021         |\n",
         "|     B00021         |2019-10-01 00:28:23|2019-10-01 00:34:33|          56|          56|   null|       B00021         |\n",
         "|     B00021         |2019-10-01 00:31:17|2019-10-01 00:51:52|          82|          82|   null|       B00021         |\n",
         "|              B00037|2019-10-01 00:07:41|2019-10-01 00:15:23|         264|          71|   null|                B00037|\n",
         "|              B00037|2019-10-01 00:13:38|2019-10-01 00:25:51|         264|          39|   null|                B00037|\n",
         "|              B00037|2019-10-01 00:42:40|2019-10-01 00:53:47|         264|         188|   null|                B00037|\n",
         "|              B00037|2019-10-01 00:58:46|2019-10-01 01:10:11|         264|          91|   null|                B00037|\n",
         "|              B00037|2019-10-01 00:09:49|2019-10-01 00:14:37|         264|          71|   null|                B00037|\n",
         "|              B00037|2019-10-01 00:22:35|2019-10-01 00:36:53|         264|          35|   null|                B00037|\n",
         "|              B00037|2019-10-01 00:54:27|2019-10-01 01:03:37|         264|          61|   null|                B00037|\n",
         "|              B00037|2019-10-01 00:08:12|2019-10-01 00:28:47|         264|         198|   null|                B00037|\n",
         "|              B00053|2019-10-01 00:05:24|2019-10-01 00:53:03|         264|         264|   null|                  #N/A|\n",
         "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
         "only showing top 20 rows\n",
         "\n"
        ]
       }
      ],
      "source": [
       "from pyspark.sql import types\n",
       "schema = types.StructType(\n",
       "    [\n",
       "        types.StructField('dispatching_base_num', types.StringType(), True), \n",
       "    types.StructField('pickup_datetime', types.TimestampType(), True), \n",
       "    types.StructField('dropOff_datetime', types.TimestampType(), True), \n",
       "    types.StructField('PUlocationID', types.IntegerType(), True), \n",
       "    types.StructField('DOlocationID', types.IntegerType(), True), \n",
       "    types.StructField('SR_Flag', types.StringType(), True), \n",
       "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
       "    ]\n",
       "    )\n",
       "df_data = spark.read \\\n",
       "    .option(\"header\", \"true\") \\\n",
       "    .schema(schema) \\\n",
       "    .csv('fhv_tripdata_2019-10.csv.gz')\n",
       "\n",
       "df_data.show()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a7d0afe4-eb19-4b01-980a-97705e2cbdc8",
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "                                                                                \r"
        ]
       }
      ],
      "source": [
       "df_data = df_data.repartition(6)\n",
       "df_data.write.parquet(\"fhv_parquet\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d7a4e6c7-d850-48b9-9d3f-7e6f968a5b80",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "6.450909614562988\n"
        ]
       }
      ],
      "source": [
       "# get average size of parquet files\n",
       "import os\n",
       "\n",
       "sizes = []\n",
       "\n",
       "# Iterate over each file\n",
       "dir = os.path.join(os.getcwd(), \"fhv_parquet\")\n",
       "for filename in os.listdir(dir):\n",
       "    # Check if the file has the desired extension\n",
       "    if filename.endswith('.parquet'):\n",
       "        # Get the full file path\n",
       "        file_path = os.path.join(dir, filename)\n",
       "        # Get the file size in bytes\n",
       "        file_size_bytes = os.path.getsize(file_path)\n",
       "        # Convert the size to megabytes\n",
       "        file_size_mb = file_size_bytes / (1024 * 1024)\n",
       "        # Append the file name and size to the list\n",
       "        sizes.append(file_size_mb)\n",
       "\n",
       "print(sum(sizes)/len(sizes))\n"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a38ef4e6-23e5-4170-88a2-0cb17e97f45d",
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "[Stage 19:>                                                         (0 + 1) / 1]\r"
        ]
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "+--------+\n",
         "|count(1)|\n",
         "+--------+\n",
         "|   62610|\n",
         "+--------+\n",
         "\n"
        ]
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "                                                                                \r"
        ]
       }
      ],
      "source": [
       "# count trip data at 15th Oct\n",
       "\n",
       "df_data.registerTempTable(\"trips\")\n",
       "\n",
       "spark.sql(\"\"\"\n",
       "select count(*) from trips \n",
       "where trips.pickup_datetime \n",
       "between '2019-10-15 00:00:00' and '2019-10-15 23:59:59'\n",
       "\"\"\").show()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 40,
      "id": "b20cc9f7-d502-4183-adaf-3c759112929b",
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "[Stage 34:>                                                         (0 + 1) / 1]\r"
        ]
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "+----------------------------------------------------------------------------------------------------------------------------+\n",
         "|(max((unix_timestamp(dropOff_datetime, yyyy-MM-dd HH:mm:ss) - unix_timestamp(pickup_datetime, yyyy-MM-dd HH:mm:ss))) / 3600)|\n",
         "+----------------------------------------------------------------------------------------------------------------------------+\n",
         "|                                                                                                                    631152.5|\n",
         "+----------------------------------------------------------------------------------------------------------------------------+\n",
         "\n"
        ]
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "                                                                                \r"
        ]
       }
      ],
      "source": [
       "# get longest trip\n",
       "spark.sql(\"\"\"\n",
       "select max(unix_timestamp(trips.dropOff_datetime) - unix_timestamp(trips.pickup_datetime)) / 3600 from trips \n",
       "\n",
       "\"\"\").show()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 41,
      "id": "61066b3c-f98a-46d9-b583-4e6534f549c5",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "--2024-03-04 22:35:51--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv\n",
         "Resolving github.com (github.com)... 140.82.121.4\n",
         "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
         "HTTP request sent, awaiting response... 302 Found\n",
         "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T203551Z&X-Amz-Expires=300&X-Amz-Signature=fbffb0034e9613d241fa77f33a86f708f686951070e22a8de4c9b298581d7abe&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream [following]\n",
         "--2024-03-04 22:35:52--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/5a2cc2f5-b4cd-4584-9c62-a6ea97ed0e6a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T203551Z&X-Amz-Expires=300&X-Amz-Signature=fbffb0034e9613d241fa77f33a86f708f686951070e22a8de4c9b298581d7abe&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dtaxi_zone_lookup.csv&response-content-type=application%2Foctet-stream\n",
         "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
         "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
         "HTTP request sent, awaiting response... 200 OK\n",
         "Length: 12322 (12K) [application/octet-stream]\n",
         "Saving to: ‘taxi_zone_lookup.csv’\n",
         "\n",
         "taxi_zone_lookup.cs 100%[===================>]  12.03K  --.-KB/s    in 0.003s  \n",
         "\n",
         "2024-03-04 22:35:52 (3.71 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\n",
         "\n"
        ]
       }
      ],
      "source": [
       "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 42,
      "id": "eceb4225-0667-4ee6-b4f6-6bad01e52a56",
      "metadata": {},
      "outputs": [],
      "source": [
       "df_zones = spark.read \\\n",
       "    .option(\"header\", \"true\") \\\n",
       "    .csv('taxi_zone_lookup.csv')"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 43,
      "id": "a963fa91-4337-4e85-8715-f0022d9ba222",
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "+----------+-------------+--------------------+------------+\n",
         "|LocationID|      Borough|                Zone|service_zone|\n",
         "+----------+-------------+--------------------+------------+\n",
         "|         1|          EWR|      Newark Airport|         EWR|\n",
         "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
         "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
         "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
         "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
         "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
         "|         7|       Queens|             Astoria|   Boro Zone|\n",
         "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
         "|         9|       Queens|          Auburndale|   Boro Zone|\n",
         "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
         "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
         "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
         "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
         "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
         "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
         "|        16|       Queens|             Bayside|   Boro Zone|\n",
         "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
         "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
         "|        19|       Queens|           Bellerose|   Boro Zone|\n",
         "|        20|        Bronx|             Belmont|   Boro Zone|\n",
         "+----------+-------------+--------------------+------------+\n",
         "only showing top 20 rows\n",
         "\n"
        ]
       }
      ],
      "source": [
       "df_zones.show()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 44,
      "id": "0359836e-c1d3-44d7-8ab8-9155daac482a",
      "metadata": {},
      "outputs": [],
      "source": [
       "df_joined = df_data.join(df_zones, df_data.PUlocationID == df_zones.LocationID)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 46,
      "id": "15ff35c1-e96f-4488-89f0-3ae1f562e6e2",
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "/home/ahmed/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
         "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
        ]
       }
      ],
      "source": [
       "df_zones.registerTempTable(\"zones\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 58,
      "id": "6f11636d-ce2b-4cf3-b711-f100cab4f8d3",
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "[Stage 56:>                                                         (0 + 1) / 1]\r"
        ]
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "+---+------+-----------+\n",
         "|cnt|loc_id|       Zone|\n",
         "+---+------+-----------+\n",
         "|  1|     2|Jamaica Bay|\n",
         "+---+------+-----------+\n",
         "\n"
        ]
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "                                                                                \r"
        ]
       }
      ],
      "source": [
       "spark.sql(\"\"\"\n",
       "select cnt, loc_id , zones.Zone from (\n",
       "select count(*) as cnt, trips.PUlocationID as loc_id \n",
       "from trips\n",
       "group by trips.PUlocationID\n",
       ") as data\n",
       "left join zones on data.loc_id = zones.LocationID\n",
       "order by cnt\n",
       "limit 1\n",
       "\n",
       "\"\"\").show()"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "id": "14527c26-716f-43f5-b8fd-a0f5810513d3",
      "metadata": {},
      "outputs": [],
      "source": []
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   